logging:
  level:
    ROOT: INFO
    # set the 3 lines to warn to suppress large config list output on startup
    org.apache.kafka.clients.admin.AdminClientConfig: WARN
    org.apache.kafka.clients.producer.ProducerConfig: WARN
    org.apache.kafka.clients.consumer.ConsumerConfig: WARN
    # Suppress "Node 0 disconnected." (INFO) messages and "Broker may not be available" messages (WARN).
    org.apache.kafka.clients.NetworkClient: ERROR
    # Suppress "Found no committed offset for partition ..." messages (INFO)
    org.apache.kafka.clients.consumer.internals.ConsumerCoordinator: WARN
    # Suppress "Resetting offset for partition ..." messages (INFO)
    org.apache.kafka.clients.consumer.internals.SubscriptionState: WARN

spring:
  application:
    name: schedule
  kafka:
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.ByteArraySerializer
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
      max-poll-records: 1
    bootstrap-servers: 'localhost:9092'
    auto-create-topics: false
    jaas:
      enabled: false
    security:
      protocol: PLAINTEXT
    properties:
      sasl:
        mechanism: PLAIN
  cloud:
    stream:
      default:
        # this setting dictates whether to commit the offset after each record is processed.
        ack-each-record: true
        # Whether to reset offsets on the consumer to the value provided by startOffset.
        reset-offsets: true
      kafka:
        binder:
          auto-create-topics: false
      # which steps are performed?
      function.definition: 'processSchedule;processAgentA01;processAgentA02;processAgentA03;processResumeB01;processResumeB02;processNotify'
      bindings:
        # PROCESSOR processSchedule - - - - - - - - - - - - - - - - - - - -
        processSchedule-in-0:
          group: ${application.id.processSchedule}
          destination: ${application.topics.topic-job-accepted}
          consumer: # consumer properties on each function (processor) level
            auto-startup: true
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        processSchedule-out-error:
          destination: ${application.topics.topic-job-accepted-err}
        # PROCESSOR processResumeB01 - - - - - - - - - - - - - - - - - - - -
        processResumeB01-in-0:
          group: ${application.id.processResume}-B01
          destination: ${application.topics.topic-job-paused}-B01
          consumer: # consumer properties on each function (processor) level
            auto-startup: false # !!! No auto startup
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        # PROCESSOR processResumeB02 - - - - - - - - - - - - - - - - - - - -
        processResumeB02-in-0:
          group: ${application.id.processResume}-B02
          destination: ${application.topics.topic-job-paused}-B02
          consumer: # consumer properties on each function (processor) level
            auto-startup: false # !!! No auto startup
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        # PROCESSOR processAgentA01 - - - - - - - - - - - - - - - - - - - -
        processAgentA01-in-0:
          group: ${application.id.processAgent}-A01
          destination: ${application.topics.topic-job-scheduled}-A01
          consumer: # consumer properties on each function (processor) level
            auto-startup: true
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        # PROCESSOR processAgentA02 - - - - - - - - - - - - - - - - - - - -
        processAgentA02-in-0:
          group: ${application.id.processAgent}-A02
          destination: ${application.topics.topic-job-scheduled}-A02
          consumer: # consumer properties on each function (processor) level
            auto-startup: true
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        # PROCESSOR processAgentA03 - - - - - - - - - - - - - - - - - - - -
        processAgentA03-in-0:
          group: ${application.id.processAgent}-A03
          destination: ${application.topics.topic-job-scheduled}-A03
          consumer: # consumer properties on each function (processor) level
            auto-startup: true
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        # PROCESSOR processNotify - - - - - - - - - - - - - - - - - - - -
        processNotify-in-0:
          group: ${application.id.processNotify}
          destination: ${application.topics.topic-job-completed}
          consumer: # consumer properties on each function (processor) level
            auto-startup: true
            concurrency: 1 # See "2.19.4 Special note on concurrency" - translated to num.stream.thread
        processNotify-out-0:
          destination: ${application.topics.topic-job-notified}
        processNotify-out-error:
          destination: ${application.topics.topic-job-completed-err}
management:
  endpoints:
    web:
      exposure:
        include: ['health', 'info', 'bindings', 'logfile', 'metrics', 'configprops', 'env', 'kafkastreamstopology']
  endpoint:
    health:
      show-details: ALWAYS
  health:
    binders:
      enabled: true # is default

application:
  loadProcessStatus:
    fixedRateMs: 20000
    initialDelayMs: 1000
  job-admin-scheme: 'http'
  job-admin-host: 'localhost:8093'
  job-admin-pathAll: '/api/processes'

  topics:
    topic-job-accepted: job-accepted
    topic-job-accepted-err: job-accepted-err
    topic-job-scheduled: job-scheduled
    topic-job-scheduled-err: job-scheduled-err
    topic-job-paused: job-paused
    topic-job-paused-err: job-paused-err
    topic-job-completed: job-completed
    topic-job-completed-err: job-completed-err
    topic-job-failed: job-failed
    topic-job-failed-err: job-failed-err
    topic-job-notified: job-notified
    topic-job-delivered: job-delivered
  id:
    # the id is used as the consumer group id, so it has to be configurable
    processSchedule: processSchedule
    processAgent: processAgent
    processResume: processResume
    processNotify: processNotify
